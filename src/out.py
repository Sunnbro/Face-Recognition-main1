# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'recognition.ui'
#
# Created by: PyQt5 UI code generator 5.15.4
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.

from PyQt5.QtGui import QImage, QPixmap
from PyQt5 import QtCore, QtGui, QtWidgets
import cv2
import sqlite3
# import numpy as np
import datetime
import pickle
from PyQt5.QtCore import pyqtSlot, QTimer, QDate, Qt
from PyQt5.QtWidgets import QDialog,QMessageBox
from PyQt5.uic import loadUi
# import csv


face_cascade = cv2.CascadeClassifier(r'C:/Users/Hp/Desktop/Face-Recognition-main/src/cascades/data/haarcascade_frontalface_alt2.xml')
eye_cascade = cv2.CascadeClassifier(r'C:/Users/Hp/Desktop/Face-Recognition-main/src/cascades/data/haarcascade_eye.xml')
smile_cascade = cv2.CascadeClassifier(r'C:/Users/Hp/Desktop/Face-Recognition-main/src/cascades/data/haarcascade_smile.xml')
recognizer = cv2.face.LBPHFaceRecognizer_create()
recognizer.read(r"C:/Users/Hp/Desktop/Face-Recognition-main/src/recognizers/face-trainner.yml")
labels = {"person_name": 1}
with open(r"C:/Users/Hp/Desktop/Face-Recognition-main/src/pickles/face-labels.pickle", 'rb') as f:
	og_labels = pickle.load(f)
	labels = {v:k for k,v in og_labels.items()}


class Ui_OutputDialog(QDialog):

	def __init__(self):
		super(Ui_OutputDialog, self).__init__()
		loadUi(r"C:/Users/Hp/Desktop/Face-Recognition-main/src/recognition.ui", self)
		# self.aboutToQuit.connect(self.closeEvent)
		#Update time
		now = QDate.currentDate()
		current_date = now.toString('ddd dd MMMM')
		self.Date_Label.setText(current_date)
		current_time = datetime.datetime.now().strftime("%I:%M %p")
		self.Time_Label.setText(current_time)
		self.conn =None
		self.cursor=None
		self.image = None
		self.name = 'unknown'

		self.ClockInButton.clicked.connect(self.check_in)
		self.ClockOutButton.clicked.connect(self.check_out)

	

	@pyqtSlot()
	def startVideo(self, camera_name):
		"""
		:param camera_name: link of camera or usb camera
		:return:
		"""
		if len(camera_name) == 1:
			self.capture = cv2.VideoCapture(int(camera_name))
		else:
			self.capture = cv2.VideoCapture(camera_name)
		self.timer = QTimer(self)  # Create Timer
		self.timer.timeout.connect(self.update_frame)  # Connect timeout to the output function
		self.timer.start(10)  # emit the timeout() signal at x=40ms

		self.connect()

	def check_in(self):

			if (self.name != 'unknown'):

				self.cursor.execute(f""" select name from pointage where date='{datetime.datetime.now().strftime('%d-%m-%Y')}' and name='{self.name}' """)
				res=self.cursor.fetchall()
				# print(res)

				if res == [] :            
							buttonReply = QMessageBox.question(self, 'Welcome ' + self.name, 'Are you Clocking In?' ,
															   QMessageBox.Yes | QMessageBox.No, QMessageBox.No)
							self.ClockInButton.setEnabled(False)								   
															   
															  
							if buttonReply == QMessageBox.Yes:
								self.cursor.execute(f"""insert into pointage (name ,date ,checkin , total) values 
								('{self.name}','{datetime.datetime.now().strftime('%d-%m-%Y')}','{datetime.datetime.now().strftime('%H:%M')}','0')
								""")
								self.conn.commit()

								print(f"clocking in at {datetime.datetime.now().strftime('%d-%m-%Y')}")
								print(f"clocking in at {datetime.datetime.now().strftime('%H:%M')}")
								
								self.ClockInButton.setEnabled(True)
							else:
								self.ClockInButton.setEnabled(True)
								print('Not clicked.')


	def check_out(self):
		
		if (self.name != 'unknown'):

				self.cursor.execute(f""" select checkin from pointage where date='{datetime.datetime.now().strftime('%d-%m-%Y')}'
				 and name='{self.name}'  and checkout is NULL""")

				res=self.cursor.fetchone()
				print(res)
				

				if res :  
					

							buttonReply = QMessageBox.question(self, 'Hello ' + self.name, 'Are you Clocking Out?',
		 													  QMessageBox.Yes | QMessageBox.No, QMessageBox.No)

							
							if buttonReply == QMessageBox.Yes:					   

		 					
								self.ClockOutButton.setChecked(False)

								time=datetime.datetime.now().strftime('%H:%M')
								totalh= int(time[:2]) - int(res[0][:2])
								totalm=  int(time[3:]) - int(res[0][3:]) 
								total=f"{totalh}:{totalm}"


								self.cursor.execute(f""" update pointage set checkout='{time}' , total ='{total}' where date='{datetime.datetime.now().strftime('%d-%m-%Y')}'
								and name='{self.name}'  and checkout is NULL
								""")
								self.conn.commit()
								self.ClockOutButton.setEnabled(True)
				
							else:
								self.ClockOutButton.setEnabled(True)
								print('Not clicked.')          
			
		



		
	def face_rec_(self, frame):
		"""
		:param frame: frame from camera
		:param encode_list_known: known face encoding
		:param class_names: known face names
		:return:
		"""

		
		# csv

		# def mark_attendance(name):
		# 	"""
		# 	:param name: detected face known or unknown one
		# 	:return:
		# 	"""
		# 	if self.ClockInButton.isChecked():
		# 		self.ClockInButton.setEnabled(False)
		# 		with open('Attendance.csv', 'a') as f:
		# 				if (name != 'unknown'):
		# 					buttonReply = QMessageBox.question(self, 'Welcome ' + name, 'Are you Clocking In?' ,
		# 													   QMessageBox.Yes | QMessageBox.No, QMessageBox.No)
															   
															  
		# 					if buttonReply == QMessageBox.Yes:

		# 						date_time_string = datetime.datetime.now().strftime("%y/%m/%d %H:%M:%S")
		# 						f.writelines(f'\n{name},{date_time_string},Clock In')
		# 						# self.ClockInButton.setChecked(False)

		# 						# self.NameLabel.setText(name)
		# 						# self.StatusLabel.setText('Clocked In')
		# 						# self.HoursLabel.setText('Measuring')
		# 						# self.MinLabel.setText('')

		# 						#self.CalculateElapse(name)
		# 						#print('Yes clicked and detected')
		# 						# self.Time1 = datetime.datetime.now()
		# 						#print(self.Time1)
		# 						self.ClockInButton.setEnabled(True)
		# 					else:
		# 						self.ClockInButton.setEnabled(True)
		# 						print('Not clicked.')
							   
								
		# 	elif self.ClockOutButton.isChecked():
		# 		self.ClockOutButton.setEnabled(False)
		# 		with open('Attendance.csv', 'a') as f:
		# 				if (name != 'unknown'):
		# 					buttonReply = QMessageBox.question(self, 'Cheers ' + name, 'Are you Clocking Out?',
		# 													  QMessageBox.Yes | QMessageBox.No, QMessageBox.No)
		# 					if buttonReply == QMessageBox.Yes:
		# 						date_time_string = datetime.datetime.now().strftime("%y/%m/%d %H:%M:%S")
		# 						f.writelines(f'\n{name},{date_time_string},Clock Out')
		# 						self.ClockOutButton.setChecked(False)

		# 						# self.NameLabel.setText(name)
		# 						# self.StatusLabel.setText('Clocked Out')
		# 						# self.Time2 = datetime.datetime.now()
		# 						#print(self.Time2)

		# 						self.ElapseList(name)
		# 						self.TimeList2.append(datetime.datetime.now())
		# 						CheckInTime = self.TimeList1[-1]
		# 						CheckOutTime = self.TimeList2[-1]
		# 						self.ElapseHours = (CheckOutTime - CheckInTime)
		# 						# self.MinLabel.setText("{:.0f}".format(abs(self.ElapseHours.total_seconds() / 60)%60) + 'm')
		# 						# self.HoursLabel.setText("{:.0f}".format(abs(self.ElapseHours.total_seconds() / 60**2)) + 'h')
		# 						self.ClockOutButton.setEnabled(True)
		# 					else:
		# 						self.ClockOutButton.setEnabled(True)
		# 						print('Not clicked.')
								

		# face recognition
		# # # # # faces_cur_frame = face_recognition.face_locations(frame)
		# # # # # encodes_cur_frame = face_recognition.face_encodings(frame, faces_cur_frame)
		# # # # # # count = 0
		# # # # # for encodeFace, faceLoc in zip(encodes_cur_frame, faces_cur_frame):
		# # # # # 	match = face_recognition.compare_faces(encode_list_known, encodeFace, tolerance=0.50)
		# # # # # 	face_dis = face_recognition.face_distance(encode_list_known, encodeFace)
		# # # # # 	name = "unknown"
		# # # # # 	best_match_index = np.argmin(face_dis)
		# # # # # 	# print("s",best_match_index)
		# # # # # 	if match[best_match_index]:
		# # # # # 		name = class_names[best_match_index].upper()
		# # # # # 		y1, x2, y2, x1 = faceLoc
		# # # # # 		cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
		# # # # # 		cv2.rectangle(frame, (x1, y2 - 20), (x2, y2), (0, 255, 0), cv2.FILLED)
		# # # # # 		cv2.putText(frame, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)
		# # # # # 	# mark_attendance(name)
		scale_percent = 120 # percent of original size
		width = int(frame.shape[1] * scale_percent / 100)
		height = int(frame.shape[0] * scale_percent / 100)
		dim = (width, height)
		frame= cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)
		####################
		gray  = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
		faces = face_cascade.detectMultiScale(gray, scaleFactor=1.5, minNeighbors=5)
		self.name="unknown"
		for (x, y, w, h) in faces:
			#print(x,y,w,h)
			roi_gray = gray[y:y+h, x:x+w] #(ycord_start, ycord_end)
			roi_color = frame[y:y+h, x:x+w]
		
			self.name="unknown"
			# recognize? deep learned model predict keras tensorflow pytorch scikit learn
			id_, conf = recognizer.predict(roi_gray)
			if conf>=4 and conf <= 75:
				
				#print(labels[id_])
				font = cv2.FONT_HERSHEY_SIMPLEX
				self.name = labels[id_]
				# print(f"my name is {name}")
				color = (255, 255, 255)
				stroke = 2
				cv2.putText(frame, self.name, (x,y), font, 1, color, stroke, cv2.LINE_AA)
				img_item = "7.png"
				cv2.imwrite(img_item, roi_color)
				color = (255, 0, 0) #BGR 0-255 
				stroke = 2
				end_cord_x = x + w
				end_cord_y = y + h
				cv2.rectangle(frame, (x, y), (end_cord_x, end_cord_y), color, stroke)
				
		# mark_attendance(name)
			
		return frame

	# def showdialog(self):
	# 	msg = QMessageBox()
	# 	msg.setIcon(QMessageBox.Information)

	# 	msg.setText("This is a message box")
	# 	msg.setInformativeText("This is additional information")
	# 	msg.setWindowTitle("MessageBox demo")
	# 	msg.setDetailedText("The details are as follows:")
	# 	msg.setStandardButtons(QMessageBox.Ok | QMessageBox.Cancel)


	# def ElapseList(self,name):
	# 	with open('Attendance.csv', "r") as csv_file:
	# 		csv_reader = csv.reader(csv_file, delimiter=',')
	# 		line_count = 2

	# 		Time1 = datetime.datetime.now()
	# 		Time2 = datetime.datetime.now()
	# 		for row in csv_reader:
	# 			for field in row:
	# 				if field in row:
	# 					if field == 'Clock In':
	# 						if row[0] == name:
	# 							#print(f'\t ROW 0 {row[0]}  ROW 1 {row[1]} ROW2 {row[2]}.')
	# 							Time1 = (datetime.datetime.strptime(row[1], '%y/%m/%d %H:%M:%S'))
	# 							self.TimeList1.append(Time1)
	# 					if field == 'Clock Out':
	# 						if row[0] == name:
	# 							#print(f'\t ROW 0 {row[0]}  ROW 1 {row[1]} ROW2 {row[2]}.')
	# 							Time2 = (datetime.datetime.strptime(row[1], '%y/%m/%d %H:%M:%S'))
	# 							self.TimeList2.append(Time2)
	# 							#print(Time2)





	def update_frame(self):
		ret, self.image = self.capture.read()
		self.displayImage(self.image, 1)
		current_time = datetime.datetime.now().strftime("%I:%M %p")
		self.Time_Label.setText(current_time)
		

	def displayImage(self, image, window=1):
		"""
		:param image: frame from camera
		:param encode_list: known face encoding list
		:param class_names: known face names
		:param window: number of window
		:return:
		"""
		image = cv2.resize(image, (640, 480))
		try:
			image = self.face_rec_(image)
		except Exception as e:
			print(e)
		qformat = QImage.Format_Indexed8
		if len(image.shape) == 3:
			if image.shape[2] == 4:
				qformat = QImage.Format_RGBA8888
			else:
				qformat = QImage.Format_RGB888
		outImage = QImage(image, image.shape[1], image.shape[0], image.strides[0], qformat)
		outImage = outImage.rgbSwapped()

		if window == 1:
			self.imgLabel.setPixmap(QPixmap.fromImage(outImage))
			self.imgLabel.setScaledContents(True)
	
	
	
	def connect(self):
		self.conn=sqlite3.connect("table.db")
		self.cursor=self.conn.cursor()
		self.cursor.execute(""" create table if not exists pointage (
			name text,
			date text,
			checkin text,
			checkout text,
			total text
		)
		""")








# if __name__ == "__main__":
# 	import sys
# 	app = QtWidgets.QApplication(sys.argv)
# 	OutputDialog = QtWidgets.QDialog()
# 	ui = Ui_OutputDialog()
# 	ui.setupUi(OutputDialog)
# 	OutputDialog.show()
# 	sys.exit(app.exec_())
